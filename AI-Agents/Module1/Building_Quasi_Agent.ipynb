{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a Quasi-Agent\n",
    "\n",
    "A quasi-agent is like a lightweight version of an AI agent. it acts as a smart assistant that can follow instructions step by step,\n",
    "\n",
    "but it can’t make decisions or learn from feedback like a full agent would.\n",
    "\n",
    "In this case, we’re building one that:\n",
    "\n",
    "Asks the user what they need (like a chatbot),\n",
    "Generates Python code based on that input,\n",
    "Adds documentation (docstrings),\n",
    "Creates test cases using unittest.\n",
    "It’s a controlled simulation of an AI assistant with memory, made just to practice managing context and prompt chaining."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quasi-Agent Architecture:\n",
    "The goal is to simulate an agent that helps write Python functions by walking through 3 distinct steps:\n",
    "\n",
    "1- Initial code generation: {The quasi-agent asks the user for a function description.}\n",
    "\n",
    "2- Documentation enhancement:  {1- The code from Step 1 is passed as input again. \n",
    "\n",
    "                                2- The agent adds a docstring to explain what the function does}\n",
    "\n",
    "3- Test case creation: {1- The documented function is now used as input again.\n",
    "\n",
    "                     2- The agent generates unit tests using Python’s unittest framework.}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from litellm import completion\n",
    "from typing import List, Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API key loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Get API key from environment variables\n",
    "load_dotenv()\n",
    "api_key = os.environ.get('OPENAI_API_KEY')\n",
    "\n",
    "if api_key:\n",
    "    print(\"API key loaded successfully!\")\n",
    "else:\n",
    "    print(\"Error: API key not found in .env file\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response(messages: List[Dict]) -> str:\n",
    "    \"\"\"Call LLM to get response\"\"\"\n",
    "    response = completion(\n",
    "        model=\"openai/gpt-4\",\n",
    "        messages=messages,\n",
    "        max_tokens=500\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_code_block(response: str) -> str:\n",
    "    \"\"\"Extract code block from response\"\"\"\n",
    "    if not '```' in response:\n",
    "        return response\n",
    "\n",
    "    code_block = response.split('```')[1].strip()\n",
    "    if code_block.startswith(\"python\"):\n",
    "        code_block = code_block[6:]\n",
    "\n",
    "    return code_block   \n",
    "        \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Programmatic-Prompting-for-Agents",
   "language": "python",
   "name": "programmatic-prompting-for-agents"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
