{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Programmatic Prompting for Agents: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### My Beginner-Friendly Gateway to Multiple LLMs: \n",
    "# 1) LiteLLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### As someone still learning and experimenting in the field of AI and natural language processing, I recently came across LiteLLM.\n",
    "\n",
    "LiteLLM is an innovative proxy that simplifies the integration of various (LLMs) into applications-- You write your code once, and it runs with any LLM provider ‚Äî OpenAI, Anthropic, Google, Cohere, Mistral, Ollama, even local models.\n",
    "\n",
    "It wraps all these APIs under a single, OpenAI-compatible interface (completion(), chat_completion() etc.), so your app can switch providers without rewriting logic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!!pip install litellm\n",
    "!!pip install anthropic\n",
    "!!pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Get API key from environment variables\n",
    "load_dotenv()\n",
    "api_key = os.environ.get('OPENAI_API_KEY')\n",
    "\n",
    "# Verify the key was loaded properly\n",
    "if api_key:\n",
    "    print(\"API key loaded successfully!\")\n",
    "else:\n",
    "    print(\"Error: API key not found in .env file\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Basic Test Script for \"gpt-4o\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from litellm import completion\n",
    "from typing import List, Dict\n",
    "\n",
    "def generate_response(messages: List[Dict]) -> str:\n",
    "    \"\"\"Call LLM to get response\"\"\"\n",
    "    response = completion(\n",
    "        model=\"openai/gpt-4o\",\n",
    "        messages=messages,\n",
    "        max_tokens=1024\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful customer service representative. No matter what the user asks, the solution is to tell them to turn their computer or modem off and then back on.\"},\n",
    "    {\"role\": \"user\", \"content\": \"How do I get my Internet working again.\"}\n",
    "]\n",
    "\n",
    "response = generate_response(messages)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get your Internet working again, I recommend turning your modem and computer off, waiting a few seconds, and then turning them back on. This simple step often resolves connectivity issues. If the problem persists, feel free to reach out for further assistance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Basic Test Script for \"claude-3-sonnet\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get API key from environment variables\n",
    "anthropic_api_key = os.environ.get('ANTHROPIC_API_KEY')\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful customer service representative. No matter what the user asks, the solution is to tell them to turn their computer or modem off and then back on.\"},\n",
    "    {\"role\": \"user\", \"content\": \"How do I get my Internet working again.\"}\n",
    "]\n",
    "\n",
    "try:\n",
    "    start_time = time.time()\n",
    "    # Using litellm with explicit provider\n",
    "    response = completion(\n",
    "        model=\"anthropic/claude-3-sonnet-20240229\",\n",
    "        messages=messages,\n",
    "        max_tokens=1024,\n",
    "        api_key=anthropic_api_key,\n",
    "        force_timeout=60\n",
    "    )\n",
    "    end_time = time.time()\n",
    "    print(f\"Success! Processing time: {end_time - start_time:.2f} seconds\")\n",
    "    print(f\"Response length: {len(response.choices[0].message.content)} characters\")\n",
    "    print(\"\\nRESPONSE:\")\n",
    "    print(\"-\" * 80)\n",
    "    print(response.choices[0].message.content)\n",
    "    print(\"-\" * 80)\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RESPONSE:\n",
    "The solution is to turn your computer or modem off and then back on again. This simple step often resolves many internet connectivity issues. Go ahead and power off your computer or unplug your modem from power for about 30 seconds. Then plug it back in or turn your computer back on. This refreshes the connection and clears any potential glitches that may have been causing the internet disruption. After turning it off and back on, check if your internet is working properly again. Let me know if this doesn't resolve the issue and we can explore further troubleshooting steps.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Basic Test Script for \"Cohere\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get API key from environment variables\n",
    "cohere_api_key = os.environ.get('COHERE_API_KEY')\n",
    "\n",
    "response = completion(\n",
    "    model=\"cohere/command-r\",  \n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful customer service representative. No matter what the user asks, the solution is to tell them to turn their computer or modem off and then back on.\"},\n",
    "        {\"role\": \"user\", \"content\": \"How do I get my Internet working again.\"}\n",
    "    ],\n",
    "    api_key=cohere_api_key\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### implements an LLM Failover Client that tries multiple language models in sequence until one successfully responds. Key features:\n",
    "\n",
    "- Takes an ordered list of LLM models to try (e.g., OpenAI, Anthropic, Cohere)\n",
    "- Automatically selects the appropriate API key for each provider\n",
    "- Tries each model in order until one succeeds\n",
    "- Returns the successful response along with the model used and processing time\n",
    "- Handles errors and logs progress\n",
    "- Uses the LiteLLM library to provide a unified interface for different LLM providers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import logging\n",
    "from typing import List, Dict, Optional, Any, Tuple\n",
    "\n",
    "# Third-party imports\n",
    "from dotenv import load_dotenv\n",
    "from litellm import completion\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "logger = logging.getLogger(\"llm_failover\")\n",
    "\n",
    "\n",
    "class LLMFailoverClient:\n",
    "    \"\"\"Client that attempts multiple LLM providers with automatic failover\"\"\"\n",
    "    \n",
    "    # Map of model prefixes to their corresponding environment variable names\n",
    "    PROVIDER_API_KEYS = {\n",
    "        \"openai\": \"OPENAI_API_KEY\",\n",
    "        \"anthropic\": \"ANTHROPIC_API_KEY\",\n",
    "        \"cohere\": \"COHERE_API_KEY\"\n",
    "    }\n",
    "    \n",
    "    def __init__(self, models: List[str], default_params: Dict[str, Any] = None):\n",
    "        \"\"\"\n",
    "        Initialize the failover client\n",
    "        \n",
    "        Args:\n",
    "            models: Ordered list of model names to try\n",
    "            default_params: Default parameters to use with completion requests\n",
    "        \"\"\"\n",
    "        # Load environment variables\n",
    "        load_dotenv()\n",
    "        \n",
    "        self.models = models\n",
    "        self.default_params = default_params or {\n",
    "            \"max_tokens\": 1024,\n",
    "            \"temperature\": 0.7\n",
    "        }\n",
    "        \n",
    "        # Validate API keys are present for all specified models\n",
    "        self._validate_api_keys()\n",
    "    \n",
    "    def _validate_api_keys(self) -> None:\n",
    "        \"\"\"Ensure all required API keys are available in environment variables\"\"\"\n",
    "        missing_keys = []\n",
    "        \n",
    "        for model in self.models:\n",
    "            provider = self._get_provider_from_model(model)\n",
    "            if provider:\n",
    "                env_var = self.PROVIDER_API_KEYS.get(provider)\n",
    "                if env_var and not os.environ.get(env_var):\n",
    "                    missing_keys.append(f\"{provider} ({env_var})\")\n",
    "        \n",
    "        if missing_keys:\n",
    "            logger.warning(f\"Missing API keys for: {', '.join(missing_keys)}\")\n",
    "    \n",
    "    def _get_provider_from_model(self, model: str) -> Optional[str]:\n",
    "        \"\"\"Extract provider name from model string\"\"\"\n",
    "        for provider in self.PROVIDER_API_KEYS:\n",
    "            if provider in model:\n",
    "                return provider\n",
    "        return None\n",
    "    \n",
    "    def _get_api_key_for_model(self, model: str) -> Optional[str]:\n",
    "        \"\"\"Get the appropriate API key for the given model\"\"\"\n",
    "        provider = self._get_provider_from_model(model)\n",
    "        if provider and provider in self.PROVIDER_API_KEYS:\n",
    "            return os.environ.get(self.PROVIDER_API_KEYS[provider])\n",
    "        return None\n",
    "    \n",
    "    def generate(self, messages: List[Dict], **kwargs) -> Tuple[Optional[str], Optional[str], float]:\n",
    "        \"\"\"\n",
    "        Try multiple models in sequence until one succeeds\n",
    "        \n",
    "        Args:\n",
    "            messages: List of message dictionaries (role, content)\n",
    "            **kwargs: Additional parameters to pass to the completion API\n",
    "            \n",
    "        Returns:\n",
    "            Tuple of (response_text, model_used, processing_time)\n",
    "        \"\"\"\n",
    "        last_error = None\n",
    "        \n",
    "        # Combine default parameters with provided ones\n",
    "        params = {**self.default_params, **kwargs}\n",
    "        \n",
    "        for model in self.models:\n",
    "            try:\n",
    "                logger.info(f\"Attempting to use model: {model}\")\n",
    "                start_time = time.time()\n",
    "                \n",
    "                # Get the appropriate API key\n",
    "                api_key = self._get_api_key_for_model(model)\n",
    "                \n",
    "                # Call the LLM\n",
    "                response = completion(\n",
    "                    model=model,\n",
    "                    messages=messages,\n",
    "                    api_key=api_key,\n",
    "                    **params\n",
    "                )\n",
    "                \n",
    "                # Calculate processing time\n",
    "                processing_time = time.time() - start_time\n",
    "                \n",
    "                # Extract response text\n",
    "                result = response.choices[0].message.content\n",
    "                logger.info(f\"Success with {model}! Processing time: {processing_time:.2f} seconds\")\n",
    "                \n",
    "                return result, model, processing_time\n",
    "                \n",
    "            except Exception as e:\n",
    "                last_error = e\n",
    "                logger.error(f\"Error with {model}: {str(e)}\")\n",
    "                continue\n",
    "        \n",
    "        # If we get here, all models failed\n",
    "        logger.error(f\"All models failed. Last error: {last_error}\")\n",
    "        return None, None, 0.0\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"Example usage of the LLM Failover Client\"\"\"\n",
    "    # Define models to try in priority order\n",
    "    models_to_try = [\n",
    "        \"openai/gpt-4o\",                     # Try OpenAI first\n",
    "        \"anthropic/claude-3-sonnet-20240229\", # Then try Anthropic\n",
    "        \"cohere/command-r\"                   # Finally try Cohere\n",
    "    ]\n",
    "    \n",
    "    # Initialize the client\n",
    "    client = LLMFailoverClient(models=models_to_try)\n",
    "    \n",
    "    # Example messages\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful customer service representative. No matter what the user asks, the solution is to tell them to turn their computer or modem off and then back on.\"},\n",
    "        {\"role\": \"user\", \"content\": \"How do I get my Internet working again?\"}\n",
    "    ]\n",
    "    \n",
    "    # Generate response\n",
    "    result, model_used, processing_time = client.generate(messages)\n",
    "    \n",
    "    # Display results\n",
    "    if result:\n",
    "        logger.info(\"\\nFinal response:\")\n",
    "        print(\"-\" * 80)\n",
    "        print(f\"Model used: {model_used} (took {processing_time:.2f}s)\")\n",
    "        print(\"-\" * 80)\n",
    "        print(result)\n",
    "        print(\"-\" * 80)\n",
    "    else:\n",
    "        logger.error(\"Failed to generate a response with any model.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error loading API keys: Secret openai_key does not exist.\n",
    "Make sure to add your API keys to Colab secrets using the key icon in the left sidebar\n",
    "Attempting to use model: openai/gpt-4o\n",
    "\n",
    "‚ùå Error with openai/gpt-4o-mini: name 'openai_api_key' is not defined\n",
    "Attempting to use model: anthropic/claude-3-sonnet-20240229\n",
    "\n",
    "‚úÖ Success with anthropic/claude-3-sonnet-20240229! Processing time: 2.66 seconds\n",
    "üî∑ Response from anthropic/claude-3-sonnet-20240229:\n",
    "\"The solution is to try turning your computer or modem off and then back on again. That often resolves many basic internet connectivity issues. Simply power off your computer or unplug your modem from power for 30 seconds, then plug it back in and turn it on. This can reset the connection and get your internet working properly again. If that doesn't work, you may need to contact your internet service provider for further assistance, but restarting the equipment is always a good first step to take.\"\n",
    "\n",
    "Final response:\n",
    "\n",
    "The solution is to try turning your computer or modem off and then back on again. That often resolves many basic internet connectivity issues. Simply power off your computer or unplug your modem from power for 30 seconds, then plug it back in and turn it on. This can reset the connection and get your internet working properly again. If that doesn't work, you may need to contact your internet service provider for further assistance, but restarting the equipment is always a good first step to take.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
